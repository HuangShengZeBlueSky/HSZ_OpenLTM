# convert_moirai_safetensors_to_pth.py
import torch
from safetensors import safe_open
import os
import json

# === é…ç½®è·¯å¾„ ===
SAFETENSORS_PATH = "/home/ubuntu/zhaojia/checkpoints/Moirai/model.safetensors"
CONFIG_PATH = "/home/ubuntu/zhaojia/checkpoints/Moirai/config.json"          # å¯é€‰ï¼Œç”¨äºéªŒè¯
OUTPUT_PTH_PATH = "/home/ubuntu/zhaojia/checkpoints/Moirai/moirai-1.1-R-base.pth"

# === åŠ è½½ configï¼ˆå¯é€‰ï¼‰===
if os.path.exists(CONFIG_PATH):
    with open(CONFIG_PATH, "r") as f:
        config = json.load(f)
    print("ğŸ” æ¨¡å‹é…ç½®:")
    print(f"   d_model: {config.get('d_model', 'N/A')}")
    print(f"   num_layers: {config.get('num_layers', 'N/A')}")

# === åŠ è½½ safetensors æƒé‡ ===
print("\nğŸ“¦ æ­£åœ¨åŠ è½½ model.safetensors ...")
state_dict = {}
with safe_open(SAFETENSORS_PATH, framework="pt", device="cpu") as f:
    for key in f.keys():
        state_dict[key] = f.get_tensor(key)

print(f"âœ… å…±åŠ è½½ {len(state_dict)} ä¸ªå‚æ•°")

# === æå– backbone å¹¶ç§»é™¤å‰ç¼€ ===
# Moirai çš„å®Œæ•´æ¨¡å‹ç»“æ„æ˜¯ï¼šMoiraiForPrediction(backbone=PatchTSMixer...)
# OpenLTM å¾®è°ƒæ—¶é€šå¸¸åªéœ€è¦ backbone éƒ¨åˆ†ï¼Œä¸”ä¸å¸¦ 'backbone.' å‰ç¼€
backbone_state = {}
for k, v in state_dict.items():
    if k.startswith("backbone."):
        new_k = k[len("backbone."):]  # ç§»é™¤ 'backbone.' å‰ç¼€
        backbone_state[new_k] = v

print(f"âœ‚ï¸  æå– backbone å‚æ•°: {len(backbone_state)} ä¸ª")

# === ä¿å­˜ä¸º .pth ===
torch.save(backbone_state, OUTPUT_PTH_PATH)
print(f"\nğŸ‰ æˆåŠŸä¿å­˜ Moirai backbone æƒé‡åˆ°:\n   {OUTPUT_PTH_PATH}")